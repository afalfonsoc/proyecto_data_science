{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b102bcec-8e77-4a37-a63c-f82afd562dc5",
   "metadata": {},
   "source": [
    "### Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91f82308-a012-4761-9f6b-98d938cd6315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "514ec93c-f4e4-4789-8746-dd0a6d0d9b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\andres\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03928058-506d-4f6f-b2c2-fb5084882213",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer \n",
    "\n",
    "def lemmatize_stemming(text):\n",
    "    ps = PorterStemmer()\n",
    "    return ps.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text): #  gensim.utils.simple_preprocess tokeniza el texto\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a669968-b736-4372-87d0-6806494c1caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"datos/All_posts_comments.csv\")\n",
    "data_text = data[['comment']]\n",
    "data_text['index'] = data_text.index\n",
    "documents = data_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaca79c1-99e3-4589-b53b-419090ff2b88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113310\n",
      "                                             comment  index\n",
      "0  Hi u/radome9! Welcome to r/RussiaUkraineWar202...      0\n",
      "1  How fucked up is it that the promise of NOT be...      1\n",
      "2  * Shooting your commanding officer? 8 years.\\n...      2\n",
      "3                                           Glorious      3\n",
      "4  Hi u/MrAutoFem! Welcome to r/RussiaUkraineWar2...      4\n"
     ]
    }
   ],
   "source": [
    "print(len(documents))\n",
    "print(documents[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec5734e6-b58f-43f5-a218-bef225f1aaca",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72b7e67f-9e67-41e7-9097-9a1c9067376a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "documento original: \n",
      "['No', 'its', 'not', 'likely', 'and', 'I', \"won't\", 'happen', 'the', 'next', '10years.']\n",
      "\n",
      "\n",
      " documento tokenizado y lematizado: \n",
      "['like', 'happen', 'year']\n"
     ]
    }
   ],
   "source": [
    "doc_sample = documents[documents['index'] == 4310].values[0][0]\n",
    "print('documento original: ')\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n documento tokenizado y lematizado: ')\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b86e56-e2c8-4e72-b80d-36b0bb280e25",
   "metadata": {},
   "source": [
    "### Preprocesamiento de textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "302e709c-99c2-439a-aebc-cf4fdc853b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [radom, welcom, heavili, moder, subreddit, not...\n",
       "1    [fuck, promis, exchang, incent, russian, want,...\n",
       "2    [shoot, command, offic, year, voluntarili, sur...\n",
       "3                                            [gloriou]\n",
       "4    [mrautofem, welcom, heavili, moder, subreddit,...\n",
       "5                                       [wrong, photo]\n",
       "6                [look, modern, soviet, helicopt, see]\n",
       "7                                     [portug, ukrain]\n",
       "8                                  [know, spare, part]\n",
       "9    [photo, right, type, http, wikipedia, wiki, ka...\n",
       "Name: comment, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs = documents['comment'].map(preprocess)\n",
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b906467f-73c1-412f-b65a-5167ab380d31",
   "metadata": {},
   "source": [
    "### Construcción del diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e7f0bb7-325e-4da7-a04b-01259c3b06e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 access\n",
      "1 account\n",
      "2 action\n",
      "3 automat\n",
      "4 ban\n",
      "5 behaviour\n",
      "6 channel\n",
      "7 combat\n",
      "8 comment\n",
      "9 compos\n",
      "10 concern\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8709e2c-de8e-42cf-b6c0-7b1912e71c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fccab2f-3b80-4130-8b31-1160cc835052",
   "metadata": {},
   "source": [
    "### Gensim doc2bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4badace8-313a-4506-a24a-28dc0ae80a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(54, 1), (143, 1), (664, 1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "bow_corpus[4310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78d00122-7c08-4e6f-839b-ef9309e2b26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 54 (\"year\") appears 1 time.\n",
      "Word 143 (\"like\") appears 1 time.\n",
      "Word 664 (\"happen\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "bow_doc_4310 = bow_corpus[4310]\n",
    "for i in range(len(bow_doc_4310)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4310[i][0], \n",
    "                                               dictionary[bow_doc_4310[i][0]], \n",
    "bow_doc_4310[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51d5ff7-9598-4cf7-860a-1b67470fdb80",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25f643cc-5d17-4a9a-9859-d527195414c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.13667569244376987),\n",
      " (1, 0.1353607084629341),\n",
      " (2, 0.12661576773189193),\n",
      " (3, 0.26212640200876935),\n",
      " (4, 0.19907863714156343),\n",
      " (5, 0.1373504870852835),\n",
      " (6, 0.13872417094206665),\n",
      " (7, 0.13231118776071307),\n",
      " (8, 0.2637110699771633),\n",
      " (9, 0.13141564432407454),\n",
      " (10, 0.13000481571621791),\n",
      " (11, 0.1305303576717125),\n",
      " (12, 0.13776605237020875),\n",
      " (13, 0.12718974394640373),\n",
      " (14, 0.2046982467371575),\n",
      " (15, 0.13448211971982818),\n",
      " (16, 0.1357085390458957),\n",
      " (17, 0.15059003858407272),\n",
      " (18, 0.12978462073936226),\n",
      " (19, 0.1376066276389906),\n",
      " (20, 0.2626025275097364),\n",
      " (21, 0.1955393397330564),\n",
      " (22, 0.1302767942989027),\n",
      " (23, 0.12230102133027823),\n",
      " (24, 0.12585157643826309),\n",
      " (25, 0.12475935671256531),\n",
      " (26, 0.1529077162326946),\n",
      " (27, 0.14539569905177344),\n",
      " (28, 0.15857758768027683),\n",
      " (29, 0.1377292031861966),\n",
      " (30, 0.26157121710885556),\n",
      " (31, 0.13231118776071307),\n",
      " (32, 0.14736457299787353),\n",
      " (33, 0.13500456705767683),\n",
      " (34, 0.14312523291623183),\n",
      " (35, 0.08713967839965166),\n",
      " (36, 0.13375580503743997),\n",
      " (37, 0.14157425196017073),\n",
      " (38, 0.13732618172574024),\n",
      " (39, 0.1425919471454218)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be6b726-c5ba-4d3e-9c23-ac2fe7f5f2bb",
   "metadata": {},
   "source": [
    "### Corriendo LDA usando la bolsa de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a2d6633-9f3c-4871-a0e9-f0f0de0a5625",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9618dec1-cf9f-46ab-9cf6-b0cc02b415eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.067*\"russian\" + 0.016*\"ukrainian\" + 0.013*\"nice\" + 0.013*\"germani\" + 0.012*\"nazi\" + 0.012*\"know\" + 0.011*\"german\" + 0.009*\"word\" + 0.008*\"believ\" + 0.008*\"live\"\n",
      "Topic: 1 \n",
      "Words: 0.064*\"http\" + 0.054*\"thank\" + 0.048*\"follow\" + 0.044*\"remind\" + 0.040*\"appear\" + 0.038*\"subreddit\" + 0.038*\"natur\" + 0.038*\"mobil\" + 0.031*\"contribut\" + 0.031*\"ensur\"\n",
      "Topic: 2 \n",
      "Words: 0.026*\"like\" + 0.024*\"shit\" + 0.022*\"good\" + 0.020*\"look\" + 0.018*\"video\" + 0.015*\"link\" + 0.015*\"russian\" + 0.014*\"dead\" + 0.014*\"guy\" + 0.013*\"menu\"\n",
      "Topic: 3 \n",
      "Words: 0.022*\"need\" + 0.015*\"slava\" + 0.015*\"russian\" + 0.012*\"ukraini\" + 0.011*\"great\" + 0.011*\"drone\" + 0.011*\"bridg\" + 0.010*\"bomb\" + 0.008*\"drop\" + 0.008*\"like\"\n",
      "Topic: 4 \n",
      "Words: 0.033*\"fuck\" + 0.026*\"orc\" + 0.023*\"hell\" + 0.015*\"bitch\" + 0.014*\"giphi\" + 0.014*\"dude\" + 0.012*\"sourc\" + 0.012*\"http\" + 0.010*\"bastard\" + 0.009*\"deserv\"\n",
      "Topic: 5 \n",
      "Words: 0.055*\"like\" + 0.036*\"peopl\" + 0.033*\"look\" + 0.027*\"russia\" + 0.024*\"putin\" + 0.021*\"russian\" + 0.012*\"countri\" + 0.012*\"think\" + 0.011*\"want\" + 0.010*\"kill\"\n",
      "Topic: 6 \n",
      "Words: 0.047*\"section\" + 0.044*\"automat\" + 0.044*\"subreddit\" + 0.043*\"comment\" + 0.038*\"remov\" + 0.037*\"post\" + 0.035*\"verifi\" + 0.032*\"messag\" + 0.031*\"follow\" + 0.027*\"spam\"\n",
      "Topic: 7 \n",
      "Words: 0.038*\"ukrain\" + 0.033*\"russia\" + 0.018*\"russian\" + 0.014*\"militari\" + 0.011*\"go\" + 0.011*\"weapon\" + 0.009*\"armi\" + 0.008*\"forc\" + 0.008*\"fight\" + 0.007*\"nato\"\n",
      "Topic: 8 \n",
      "Words: 0.050*\"fuck\" + 0.022*\"russia\" + 0.019*\"hero\" + 0.018*\"love\" + 0.018*\"ukrain\" + 0.017*\"slava\" + 0.017*\"hope\" + 0.015*\"rest\" + 0.012*\"life\" + 0.011*\"peac\"\n",
      "Topic: 9 \n",
      "Words: 0.017*\"russia\" + 0.015*\"ukrain\" + 0.013*\"say\" + 0.012*\"know\" + 0.011*\"sure\" + 0.009*\"think\" + 0.008*\"mean\" + 0.007*\"rapid\" + 0.007*\"thing\" + 0.007*\"need\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200f0a56-c411-4af8-8db8-7a6ca141735d",
   "metadata": {},
   "source": [
    "### Corriendo  LDA usando TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ed041a9-adc0-4ac9-a588-4b22b1f33da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.021*\"good\" + 0.011*\"savevideo\" + 0.010*\"russian\" + 0.008*\"russia\" + 0.007*\"kill\" + 0.007*\"like\" + 0.006*\"peopl\" + 0.006*\"respect\" + 0.005*\"putin\" + 0.005*\"right\"\n",
      "Topic: 1 Word: 0.035*\"hero\" + 0.017*\"rest\" + 0.013*\"peac\" + 0.010*\"brave\" + 0.010*\"putin\" + 0.010*\"stupid\" + 0.008*\"savevideobot\" + 0.008*\"base\" + 0.008*\"warrior\" + 0.007*\"true\"\n",
      "Topic: 2 Word: 0.027*\"fuck\" + 0.017*\"russia\" + 0.015*\"russian\" + 0.011*\"love\" + 0.008*\"germani\" + 0.008*\"sourc\" + 0.007*\"ukrainian\" + 0.007*\"like\" + 0.006*\"bastard\" + 0.006*\"guy\"\n",
      "Topic: 3 Word: 0.010*\"translat\" + 0.008*\"russian\" + 0.008*\"like\" + 0.007*\"look\" + 0.007*\"russia\" + 0.007*\"great\" + 0.007*\"lmao\" + 0.007*\"say\" + 0.007*\"fuck\" + 0.006*\"poor\"\n",
      "Topic: 4 Word: 0.021*\"shit\" + 0.019*\"bitch\" + 0.015*\"song\" + 0.014*\"word\" + 0.013*\"piec\" + 0.012*\"real\" + 0.012*\"brother\" + 0.011*\"cool\" + 0.011*\"deport\" + 0.009*\"go\"\n",
      "Topic: 5 Word: 0.022*\"delet\" + 0.013*\"nice\" + 0.010*\"hell\" + 0.009*\"russian\" + 0.007*\"know\" + 0.007*\"come\" + 0.007*\"orc\" + 0.007*\"happi\" + 0.006*\"russia\" + 0.006*\"like\"\n",
      "Topic: 6 Word: 0.010*\"nazi\" + 0.010*\"think\" + 0.009*\"russian\" + 0.008*\"fuck\" + 0.008*\"russia\" + 0.008*\"special\" + 0.008*\"like\" + 0.007*\"look\" + 0.007*\"oper\" + 0.006*\"yeah\"\n",
      "Topic: 7 Word: 0.017*\"giphi\" + 0.012*\"dead\" + 0.010*\"hope\" + 0.008*\"stay\" + 0.008*\"russian\" + 0.008*\"damn\" + 0.007*\"ukrain\" + 0.007*\"bless\" + 0.007*\"burn\" + 0.007*\"awesom\"\n",
      "Topic: 8 Word: 0.021*\"slava\" + 0.016*\"like\" + 0.015*\"look\" + 0.014*\"ukraini\" + 0.009*\"russian\" + 0.008*\"ukrain\" + 0.008*\"send\" + 0.006*\"russia\" + 0.006*\"shoot\" + 0.006*\"sound\"\n",
      "Topic: 9 Word: 0.067*\"remov\" + 0.034*\"subreddit\" + 0.029*\"automat\" + 0.028*\"follow\" + 0.027*\"comment\" + 0.025*\"messag\" + 0.025*\"section\" + 0.023*\"post\" + 0.020*\"verifi\" + 0.018*\"action\"\n"
     ]
    }
   ],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114e977b-c1a9-4233-99d6-02388335a41f",
   "metadata": {},
   "source": [
    "### Evaluación del desempeño clasificando el documento de muestra usando el modelo LDA de bolsa de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6fcdc56-f8b1-4a0a-88b9-5b9d8e08f2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['like', 'happen', 'year']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[4310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ce8532f-47b3-460f-abf5-719f892477e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.7749541997909546\t \n",
      "Topic: 0.055*\"like\" + 0.036*\"peopl\" + 0.033*\"look\" + 0.027*\"russia\" + 0.024*\"putin\" + 0.021*\"russian\" + 0.012*\"countri\" + 0.012*\"think\" + 0.011*\"want\" + 0.010*\"kill\"\n",
      "\n",
      "Score: 0.025009844452142715\t \n",
      "Topic: 0.026*\"like\" + 0.024*\"shit\" + 0.022*\"good\" + 0.020*\"look\" + 0.018*\"video\" + 0.015*\"link\" + 0.015*\"russian\" + 0.014*\"dead\" + 0.014*\"guy\" + 0.013*\"menu\"\n",
      "\n",
      "Score: 0.025009023025631905\t \n",
      "Topic: 0.017*\"russia\" + 0.015*\"ukrain\" + 0.013*\"say\" + 0.012*\"know\" + 0.011*\"sure\" + 0.009*\"think\" + 0.008*\"mean\" + 0.007*\"rapid\" + 0.007*\"thing\" + 0.007*\"need\"\n",
      "\n",
      "Score: 0.0250083040446043\t \n",
      "Topic: 0.038*\"ukrain\" + 0.033*\"russia\" + 0.018*\"russian\" + 0.014*\"militari\" + 0.011*\"go\" + 0.011*\"weapon\" + 0.009*\"armi\" + 0.008*\"forc\" + 0.008*\"fight\" + 0.007*\"nato\"\n",
      "\n",
      "Score: 0.02500782534480095\t \n",
      "Topic: 0.067*\"russian\" + 0.016*\"ukrainian\" + 0.013*\"nice\" + 0.013*\"germani\" + 0.012*\"nazi\" + 0.012*\"know\" + 0.011*\"german\" + 0.009*\"word\" + 0.008*\"believ\" + 0.008*\"live\"\n",
      "\n",
      "Score: 0.02500583417713642\t \n",
      "Topic: 0.050*\"fuck\" + 0.022*\"russia\" + 0.019*\"hero\" + 0.018*\"love\" + 0.018*\"ukrain\" + 0.017*\"slava\" + 0.017*\"hope\" + 0.015*\"rest\" + 0.012*\"life\" + 0.011*\"peac\"\n",
      "\n",
      "Score: 0.02500237710773945\t \n",
      "Topic: 0.022*\"need\" + 0.015*\"slava\" + 0.015*\"russian\" + 0.012*\"ukraini\" + 0.011*\"great\" + 0.011*\"drone\" + 0.011*\"bridg\" + 0.010*\"bomb\" + 0.008*\"drop\" + 0.008*\"like\"\n",
      "\n",
      "Score: 0.025000980123877525\t \n",
      "Topic: 0.033*\"fuck\" + 0.026*\"orc\" + 0.023*\"hell\" + 0.015*\"bitch\" + 0.014*\"giphi\" + 0.014*\"dude\" + 0.012*\"sourc\" + 0.012*\"http\" + 0.010*\"bastard\" + 0.009*\"deserv\"\n",
      "\n",
      "Score: 0.025000816211104393\t \n",
      "Topic: 0.064*\"http\" + 0.054*\"thank\" + 0.048*\"follow\" + 0.044*\"remind\" + 0.040*\"appear\" + 0.038*\"subreddit\" + 0.038*\"natur\" + 0.038*\"mobil\" + 0.031*\"contribut\" + 0.031*\"ensur\"\n",
      "\n",
      "Score: 0.025000816211104393\t \n",
      "Topic: 0.047*\"section\" + 0.044*\"automat\" + 0.044*\"subreddit\" + 0.043*\"comment\" + 0.038*\"remov\" + 0.037*\"post\" + 0.035*\"verifi\" + 0.032*\"messag\" + 0.031*\"follow\" + 0.027*\"spam\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e61c747-c46c-4d09-8ff8-aab3979221c6",
   "metadata": {},
   "source": [
    "### Evaluación del desempeño clasificando el documento de muestra usando el modelo LDA TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce6d84aa-c2cd-4652-83ff-eadea83bc873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.7749181985855103\t \n",
      "Topic: 0.022*\"delet\" + 0.013*\"nice\" + 0.010*\"hell\" + 0.009*\"russian\" + 0.007*\"know\" + 0.007*\"come\" + 0.007*\"orc\" + 0.007*\"happi\" + 0.006*\"russia\" + 0.006*\"like\"\n",
      "\n",
      "Score: 0.02501380629837513\t \n",
      "Topic: 0.021*\"slava\" + 0.016*\"like\" + 0.015*\"look\" + 0.014*\"ukraini\" + 0.009*\"russian\" + 0.008*\"ukrain\" + 0.008*\"send\" + 0.006*\"russia\" + 0.006*\"shoot\" + 0.006*\"sound\"\n",
      "\n",
      "Score: 0.02501256950199604\t \n",
      "Topic: 0.017*\"giphi\" + 0.012*\"dead\" + 0.010*\"hope\" + 0.008*\"stay\" + 0.008*\"russian\" + 0.008*\"damn\" + 0.007*\"ukrain\" + 0.007*\"bless\" + 0.007*\"burn\" + 0.007*\"awesom\"\n",
      "\n",
      "Score: 0.025010382756590843\t \n",
      "Topic: 0.010*\"nazi\" + 0.010*\"think\" + 0.009*\"russian\" + 0.008*\"fuck\" + 0.008*\"russia\" + 0.008*\"special\" + 0.008*\"like\" + 0.007*\"look\" + 0.007*\"oper\" + 0.006*\"yeah\"\n",
      "\n",
      "Score: 0.025010032579302788\t \n",
      "Topic: 0.021*\"good\" + 0.011*\"savevideo\" + 0.010*\"russian\" + 0.008*\"russia\" + 0.007*\"kill\" + 0.007*\"like\" + 0.006*\"peopl\" + 0.006*\"respect\" + 0.005*\"putin\" + 0.005*\"right\"\n",
      "\n",
      "Score: 0.025009503588080406\t \n",
      "Topic: 0.027*\"fuck\" + 0.017*\"russia\" + 0.015*\"russian\" + 0.011*\"love\" + 0.008*\"germani\" + 0.008*\"sourc\" + 0.007*\"ukrainian\" + 0.007*\"like\" + 0.006*\"bastard\" + 0.006*\"guy\"\n",
      "\n",
      "Score: 0.0250090304762125\t \n",
      "Topic: 0.010*\"translat\" + 0.008*\"russian\" + 0.008*\"like\" + 0.007*\"look\" + 0.007*\"russia\" + 0.007*\"great\" + 0.007*\"lmao\" + 0.007*\"say\" + 0.007*\"fuck\" + 0.006*\"poor\"\n",
      "\n",
      "Score: 0.025008199736475945\t \n",
      "Topic: 0.035*\"hero\" + 0.017*\"rest\" + 0.013*\"peac\" + 0.010*\"brave\" + 0.010*\"putin\" + 0.010*\"stupid\" + 0.008*\"savevideobot\" + 0.008*\"base\" + 0.008*\"warrior\" + 0.007*\"true\"\n",
      "\n",
      "Score: 0.0250068511813879\t \n",
      "Topic: 0.021*\"shit\" + 0.019*\"bitch\" + 0.015*\"song\" + 0.014*\"word\" + 0.013*\"piec\" + 0.012*\"real\" + 0.012*\"brother\" + 0.011*\"cool\" + 0.011*\"deport\" + 0.009*\"go\"\n",
      "\n",
      "Score: 0.02500138245522976\t \n",
      "Topic: 0.067*\"remov\" + 0.034*\"subreddit\" + 0.029*\"automat\" + 0.028*\"follow\" + 0.027*\"comment\" + 0.025*\"messag\" + 0.025*\"section\" + 0.023*\"post\" + 0.020*\"verifi\" + 0.018*\"action\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model_tfidf[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873aafdf-a24a-42ca-9908-69a5f55a3fb8",
   "metadata": {},
   "source": [
    "## Prueba del modelo con un documento no visto antes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "719f5a7b-d260-44d0-9ff6-ceb2b3ef9e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.35029685497283936\t Topic: 0.067*\"russian\" + 0.016*\"ukrainian\" + 0.013*\"nice\" + 0.013*\"germani\" + 0.012*\"nazi\"\n",
      "Score: 0.29998016357421875\t Topic: 0.055*\"like\" + 0.036*\"peopl\" + 0.033*\"look\" + 0.027*\"russia\" + 0.024*\"putin\"\n",
      "Score: 0.2096201628446579\t Topic: 0.033*\"fuck\" + 0.026*\"orc\" + 0.023*\"hell\" + 0.015*\"bitch\" + 0.014*\"giphi\"\n",
      "Score: 0.020021185278892517\t Topic: 0.038*\"ukrain\" + 0.033*\"russia\" + 0.018*\"russian\" + 0.014*\"militari\" + 0.011*\"go\"\n",
      "Score: 0.020016038790345192\t Topic: 0.050*\"fuck\" + 0.022*\"russia\" + 0.019*\"hero\" + 0.018*\"love\" + 0.018*\"ukrain\"\n",
      "Score: 0.020014991983771324\t Topic: 0.022*\"need\" + 0.015*\"slava\" + 0.015*\"russian\" + 0.012*\"ukraini\" + 0.011*\"great\"\n",
      "Score: 0.020012659952044487\t Topic: 0.064*\"http\" + 0.054*\"thank\" + 0.048*\"follow\" + 0.044*\"remind\" + 0.040*\"appear\"\n",
      "Score: 0.020012659952044487\t Topic: 0.026*\"like\" + 0.024*\"shit\" + 0.022*\"good\" + 0.020*\"look\" + 0.018*\"video\"\n",
      "Score: 0.020012659952044487\t Topic: 0.047*\"section\" + 0.044*\"automat\" + 0.044*\"subreddit\" + 0.043*\"comment\" + 0.038*\"remov\"\n",
      "Score: 0.020012659952044487\t Topic: 0.017*\"russia\" + 0.015*\"ukrain\" + 0.013*\"say\" + 0.012*\"know\" + 0.011*\"sure\"\n"
     ]
    }
   ],
   "source": [
    "unseen_document = 'How a Pentagon deal became an identity crisis for Google'\n",
    "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8716912d-0e8d-490c-9b1e-d0c27615ec9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
